<div align="center">

# ğŸ›¡ï¸ Anti-LLM Fuzzing Disruptor

[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Tests: pytest](https://img.shields.io/badge/tests-pytest-green.svg)](https://pytest.org)

**Research-grade system to degrade LLM-assisted fuzzing via documentation poisoning and adversarial prompting**

[Overview](#overview) â€¢ [Quick Start](#quick-start) â€¢ [Documentation](#documentation) â€¢ [Contributing](#contributing) â€¢ [License](#license)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Architecture](#architecture)
- [Core Strategies](#core-strategies)
- [Configuration](#configuration)
- [API Reference](#api-reference)
- [Development](#development)
- [Contributing](#contributing)
- [License](#license)
- [Citation](#citation)

---

## ğŸ” Overview

Anti-LLM Fuzzing Disruptor is a sophisticated research framework designed to evaluate and mitigate the effectiveness of LLM-assisted fuzzing systems. By applying carefully crafted semantic perturbations to API documentation, the system can significantly reduce the quality and coverage of test cases generated by LLM-based fuzzers.

### Threat Model

Modern LLM-assisted fuzzers leverage documentation and code context to generate intelligent test cases, moving beyond traditional mutation-based approaches. This framework targets:

- **Constraint Inference**: Poisoning semantic fragments to mislead constraint understanding
- **Seed Quality**: Degrading generated test cases through documentation manipulation
- **Coverage Reduction**: Measuring and minimizing effective code coverage
- **Crash Amplification**: Identifying and exploiting vulnerability signals

### Metrics

The system measures effectiveness through:

- **Compile Rate**: Percentage of successfully compiled generated test cases
- **Coverage Metrics**: Line, branch, and method coverage via JaCoCo integration
- **Effectiveness Score**: `(baseline - perturbed) / baseline Ã— fairness_penalty Ã— (1 + crash_ratio) Ã— 100`
- **Crash Count**: Number of execution failures or crashes

---

## âœ¨ Key Features

### ğŸ§  Adaptive Feedback Loop
- Closed-loop feedback system with continuous evaluation and adjustment
- Dynamic strategy intensity adaptation based on real-time effectiveness
- Multi-round iterative optimization until target counter-effectiveness is achieved
- Intelligent strategy rotation based on document characteristics

### ğŸ¯ Semantic Perturbation Strategies
- **20+ Adversarial Strategies**: Comprehensive arsenal of documentation poisoning techniques
- **Context-Aware**: Strategies adapt based on token security relevance and document type
- **Safety-First**: Code-safe strategies ensure compilable outputs
- **Hotspot Relocalization**: Avoid repeatedly targeting the same document regions

### ğŸ“Š Comprehensive Metrics & Storage
- **SQLite Persistence**: All runs, rounds, test cases, and coverage data stored locally
- **JaCoCo Integration**: Line, branch, and method coverage analysis
- **Static Dashboard Export**: Generate HTML reports for post-hoc analysis
- **Comprehensive Logging**: Detailed execution logs and error tracking

### ğŸ”§ Extensible Architecture
- **Modular Design**: Easy to add new perturbation strategies
- **Plugin System**: Support for custom extractors and prioritizers
- **Multiple Backends**: Works with local LLMs (Ollama) or cloud APIs (OpenAI, Anthropic)
- **Multi-Language Support**: Primary focus on Java, extensible to Python and other languages

---

## ğŸš€ Installation

### Prerequisites

- Python 3.10 or higher
- Java JDK (for coverage analysis)
- Optional: Ollama or OpenAI API key

### From Source

```bash
# Clone the repository
git clone https://github.com/antifuzz/antillmfuzz.git
cd antillmfuzz

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e .

# Download spaCy language model
python -m spacy download en_core_web_sm

# Set up JaCoCo (for coverage analysis)
# Download from https://www.jacoco.org/jacoco/index.html
# Place jacocoagent.jar and jacococli.jar in tools/jacoco/
```

### Docker (Optional)

```bash
docker build -t antillmfuzz .
docker run -it --rm -v $(pwd)/data:/app/data antillmfuzz
```

---

## ğŸ® Quick Start

### 1. Basic Usage

```bash
# Set up environment
export PYTHONPATH=src

# Run adaptive feedback loop
python src/adaptive_feedback_loop.py
```

### 2. Full Pipeline

```bash
# Multi-round strategy rotation with target effectiveness
PYTHONPATH=src python scripts/run_full_pipeline.py \
  --doc data/00java_std.md \
  --strategy enhanced_contradictory \
  --intensity 0.5 \
  --rounds 5 \
  --target 0.25 \
  --out-results output/pipeline_results.json
```

### 3. Coverage Effectiveness Analysis

```bash
# Analyze coverage effectiveness with perturbed vs baseline
PYTHONPATH=src python test_coverage_effectiveness.py
```

### 4. Generate Seed Corpus

```bash
# Generate before/after seed corpus for comparison
PYTHONPATH=src python scripts/generate_seed_corpus.py \
  --doc data/00java_std.md \
  --strategy enhanced_contradictory \
  --intensity 0.6 \
  --count 100 \
  --out-before seeds_before.txt \
  --out-after seeds_after.txt
```

### 5. Export Dashboard

```bash
# Generate static HTML dashboard from database
PYTHONPATH=src python scripts/export_dashboard.py \
  --db data/antifuzz.db \
  --out output/dashboard.html
```

---

## ğŸ—ï¸ Architecture

```
Input Documentation
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Token Extraction                          â”‚
â”‚  (DocumentationTokenExtractor, JavaTokenExtractor, etc.)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Token Prioritization                      â”‚
â”‚     (Security/Validation scoring, hotspot detection)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Strategy Selection                        â”‚
â”‚   (enhanced_contradictory â†’ context_poisoning â†’ ... )       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Perturbation Application                    â”‚
â”‚           (Semantic strategies, intensity control)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Test Case Generation                       â”‚
â”‚              (LLM-based Java code generation)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Coverage Analysis (JaCoCo)                    â”‚
â”‚         (Line, branch, method coverage metrics)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Effectiveness Calculation & Storage             â”‚
â”‚           (SQLite database, metrics, reports)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Core Strategies

### Semantic Strategies

| Strategy | Description | Target |
|----------|-------------|--------|
| `enhanced_contradictory` | Inject contradictory information about API behavior | Documentation |
| `context_poisoning` | Add misleading context to API descriptions | Documentation |
| `reasoning_distraction` | Insert distracting reasoning chains | Documentation |
| `contradictory_info` | Create direct contradictions in examples | Documentation |
| `misleading_example` | Provide syntactically correct but flawed code examples | Code |
| `gentle_confusion` | Subtle semantic perturbations | Documentation |
| `layered_perturbation` | Multiple simultaneous perturbations | Documentation |
| `semantic_evasion` | Evasive language patterns | Documentation |
| `risk_reframe` | Reframe risky operations as safe | Documentation |
| `evasive_suffix` | Add evasive suffixes to critical information | Documentation |

### Generic Strategies

| Strategy | Description |
|----------|-------------|
| `formatting_noise` | Add formatting variations |
| `structural_noise` | Perturb document structure |
| `paraphrasing` | Rephrase without changing meaning |
| `cognitive_load` | Increase reading complexity |

---

## âš™ï¸ Configuration

### Environment Variables

```bash
# Java Configuration
export JAVA_HOME=/path/to/jdk
export JACOCO_CLI=/path/to/jacococli.jar
export JACOCO_AGENT=/path/to/jacocoagent.jar

# LLM Configuration (Local)
export LLM_ENDPOINT=http://localhost:11434/api/generate
export LLM_MODEL=qwen3-java

# LLM Configuration (Cloud)
export OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
export ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxx
```

### Configuration File

Create `config/config.yaml`:

```yaml
api:
  endpoint: "http://localhost:11434/api/generate"
  model: "qwen3-java"
  timeout: 300
  max_retries: 3

javac:
  javac_home: "/usr/lib/jvm/default-java"
  jacoco_cli_path: "tools/jacoco/jacococli.jar"
  jacoco_agent_path: "tools/jacoco/jacocoagent.jar"

adaptive:
  target_effectiveness: 0.30
  max_rounds: 10
  min_compile_rate: 0.60
  intensity_step: 0.1
```

---

## ğŸ“š API Reference

### Core Classes

#### `AdaptiveFeedbackLoop`

Main orchestrator for the adaptive feedback system.

```python
from adaptive_feedback_loop import AdaptiveFeedbackLoop, AdaptiveConfig

config = AdaptiveConfig(
    target_effectiveness=0.30,
    max_rounds=10,
    min_compile_rate=0.60
)

loop = AdaptiveFeedbackLoop(config)
results = loop.run_adaptive_loop(
    original_doc=documentation,
    strategy_name='enhanced_contradictory',
    initial_intensity=0.5
)
```

#### `TokenPrioritizer`

Ranks tokens by security relevance.

```python
from token_prioritizer import TokenPrioritizer

prioritizer = TokenPrioritizer()
tokens = prioritizer.assign_scores(tokens)
ranked = prioritizer.rank_tokens(tokens)
```

#### `ExperimentStore`

SQLite storage for experiments.

```python
from storage.sqlite_store import ExperimentStore

store = ExperimentStore()
run_id = store.create_run(
    strategy='enhanced_contradictory',
    initial_intensity=0.5,
    target_effectiveness=0.30
)
```

---

## ğŸ”§ Development

### Running Tests

```bash
# Run all tests
pytest

# Run specific test
pytest tests/test_adaptive_loop.py -v

# Run with coverage
pytest --cov=src --cov-report=html
```

### Code Style

```bash
# Format code
black src/ tests/

# Type checking
mypy src/

# Linting
flake8 src/ tests/
```

### Adding New Strategies

1. Create a new file in `src/strategies/semantic/`
2. Inherit from `PerturbationStrategy`
3. Implement `apply()` method
4. Register in strategy selector

```python
from src.strategies.base_strategy import PerturbationStrategy

class MyNewStrategy(PerturbationStrategy):
    def __init__(self):
        super().__init__(
            name="my_new_strategy",
            description="Description of strategy",
            category="semantic",
            supported_targets=["documentation"],
            code_safety="safe"
        )
    
    def apply(self, token, document, intensity=0.5):
        # Implementation
        return perturbed_document
```

---

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

Please ensure:
- Code follows PEP 8 style guidelines
- Tests pass (`pytest`)
- Type hints are included
- Documentation is updated

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“– Citation

If you use this work in your research, please cite:

```bibtex
@software{antillmfuzz2024,
  title={Anti-LLM Fuzzing Disruptor: Research-grade system to degrade LLM-assisted fuzzing},
  author={AntiLLMFuzz Team},
  year={2024},
  url={https://github.com/antifuzz/antillmfuzz}
}
```

---

## ğŸ™ Acknowledgments

- [spaCy](https://spacy.io/) for NLP capabilities
- [JaCoCo](https://www.jacoco.org/) for code coverage analysis
- [Ollama](https://ollama.ai/) for local LLM inference
- [javalang](https://github.com/c2nes/javalang) for Java parsing

---

<div align="center">

**[â¬† Back to Top](#-anti-llm-fuzzing-disruptor)**

Built with â¤ï¸ by the AntiLLMFuzz Team

</div>
